{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\r\n",
    "import mediapipe as mp\r\n",
    "from math import hypot\r\n",
    "from ctypes import cast, POINTER\r\n",
    "from comtypes import CLSCTX_ALL\r\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cap = cv2.VideoCapture(0)\r\n",
    "mpHands = mp.solutions.hands\r\n",
    "hands = mpHands.Hands()\r\n",
    "mpDraw = mp.solutions.drawing_utils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "devices = AudioUtilities.GetSpeakers()\r\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\r\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "volMin,volMax = volume.GetVolumeRange()[:2]\r\n",
    "while True:\r\n",
    "  success, img = cap.read()\r\n",
    "  imgRBG = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
    "  result = hands.process(imgRBG)\r\n",
    "  \r\n",
    "  lmList = []\r\n",
    "  if result.multi_hand_landmarks:\r\n",
    "    for handlandmark in result.multi_hand_landmarks:\r\n",
    "      for id,lm in enumerate(handlandmark.landmark):\r\n",
    "        h,w,_ = img.shape\r\n",
    "        cx,cy = int(lm.x*w), int(lm.y*h)\r\n",
    "        lmList.append([id,cx,cy])\r\n",
    "      mpDraw.draw_landmarks(img,handlandmark,mpHands.HAND_CONNECTIONS)\r\n",
    "      \r\n",
    "  if lmList != []:\r\n",
    "    x1, y1 = lmList[4][1],lmList[4][2]\r\n",
    "    x2, y2 = lmList[8][1],lmList[8][2]\r\n",
    "    \r\n",
    "    cv2.circle(img,(x1,y1),4,(255,0,0),cv2.FILLED)\r\n",
    "    cv2.circle(img,(x2,y2),4,(255,0,0),cv2.FILLED)\r\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(255,0,0),3)\r\n",
    "    \r\n",
    "    length = hypot(x2-x1,y2-y1)\r\n",
    "    \r\n",
    "    vol = np.interp(length,[15,220], [volMin, volMax])\r\n",
    "    print(vol,length)\r\n",
    "    volume.SetMasterVolumeLevel(vol, None)\r\n",
    "    \r\n",
    "  cv2.imshow('Image', img)\r\n",
    "  if cv2.waitKey(1) & 0xff == ord('q'):\r\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "fb1a2f1df6d22449d2cae62b106950886d110ab6615fc8e683080d29fee5490a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}